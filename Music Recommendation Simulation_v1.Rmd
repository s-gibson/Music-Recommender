---
title: "Music Recommendation Simulation_v1"
output: html_notebook
---

The purpose of this program is to provide an initial framework for recommending music artists and bands to users based on their past listening history.  The program relies heavily on the functions provided in the "recommenderlab" R package (https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf).  The recommendation method is a "User Based Collaborative Filtering" (UBCF) recommendation algorithm that identifies users with similar musical preferences and then identifies items (in this case artists/bands) that high-similarity users tend to listen to in common as recommendable items to a "test" user.

The dataset that I am using is huge! Nearly 12 million observations (which are unique combinations of user and artist/band, and how many listens each user gives to each artist/band), of more than 200K unique artists by more than 300K unique users.  So while an ideal program would rely on all user-artist combinations for making recommendations to test users, it is simply to time inefficient to do so given my current software skills.  This program is intended to provide a framework for which such a simulation would be carried out, but only using a subset of the data.  The program allows for adjusting the number of users for which to consider in making a recommendation.  I've found a training set of 100 random users to be an agreeable mix of timely yet informative in recommmending artists/bands.

First, install and load the "recommenderlab" package.
```{r}
install.packages("recommenderlab")
library(recommenderlab)
```

Code for saving data environments.  It is often timely to create training datasets, so saving and being able to re-load previously created training sets (and their environment) can be a good approach to managing multiple training sets of varying size.  Note that the code saves locally, so it will require some modification to run on another computer.
```{r}
save.image("~/Documents/NYU/APSTA 2017/EDSP_v2/large data/Lastfm_sim_data.RData")
```

Code for loading data environments.
```{r}
load("large-rep/Lastfm_sim_data.RData")
```

We first need to load the full dataset (the 11 million observation one) of all users' play counts by artist.  The environment consists of 3 dataframes:
  1)  Lastfm - This is the full raw data.  Each row is a unique user-artist/band combination        and how many times said user has played a song by said artist/band.
  2)  Artist.plays - This a dataframe of all unique ARTISTS/BANDS and how many times they have       been listened to across all users (Total.plays) and how many different users have             listened to said artist/band (N.users).
  3)  User.plays - This is a dataframe of all unique USERS and how many plays they have across
      all artists/bands (Total.plays) and how many different artists/bands said user has
      listened to (N.artists).
```{r}
load("large-rep/Lastfm_data.RData")
```

Including users who have only listened to a small number of unique artists doesn't serve much purpose from an initial simulation standpoint.  For example, it could be hard to characterize the listening preferences of a user who only listens to one artist.  Let's examine the distribution of the number of unique artists that users listen to.
```{r}
plot(density(User.plays$N.artists, na.rm = T), main = "# of Unique Artists Listened to by User" )
```

For the sake of this simulation, let's only consider users who have listened to songs by no fewer than 20 different artists
```{r}
User.plays.20 <- User.plays[which(User.plays$N.artists >= 20),]
```

Now, let's draw a sample of N random users (who have listened to 20+ unique artists).  The N value can be adjusted, as well as the seed used for random sampling.  The code below creates a list of the randomly selected users, and creates a dataframe that is a subset of the full raw data that only includes the plays of the users who were randomly sampled.
```{r}
set.seed(2142017)
N_samp <- 100
samp.users <- User.plays.20$User[sample(c(1:length(User.plays.20$User)), N_samp , replace = F)]
samp.dat <- Lastfm[which(Lastfm$usersha1 %in% samp.users),]
```

Collaborative Filtering relies on the use of a "utility matrix".  This is a matrix that quantifies the preference of users for all possible "items".  Each row represents a unique user, each column represents a unique item (in this case, items are artists/bands).  And each value represents the level of preference by "User A" for "Item 1".  In a recommendation system that relies on users' ratings of items, this value might be a 1-5 "star" rating.  For my program, the number of plays represents a user's preference for an artist/band.  The code below first prints out the number of unique artists who have been listened to by the number of random users that were sampled.  This should give you a feel for the size of the utility matrix (unique artists * unique users).  Next, the code creates and fills in the utility matrix by referencing the sample data created in the code above.
**NOTE: The process of fillin in the matrix can take awhile.  Filling in a matrix of 100 unique users takes my system ~15 minutes, so considering running the code and taking a break to get lunch, check email, etc.
```{r}
print(paste("Number of unique artists in a sample of", N_samp,"users:", 
        length(unique(samp.dat$artname))))
samp.Utility <- matrix(data = NA, nrow = length(unique(samp.dat$usersha1)),
                       ncol = length(unique(samp.dat$artname)))
rownames(samp.Utility) <- unique(samp.dat$usersha1)
colnames(samp.Utility) <- unique(samp.dat$artname)

# fill in utility matrix for training
for (r in 1:nrow(samp.Utility)) {
  for (c in 1:ncol(samp.Utility)) {
    samp.Utility[r,c] <- max(samp.dat$plays[
      which(samp.dat$artname == colnames(samp.Utility)[c] &
              samp.dat$usersha1 == rownames(samp.Utility)[r])
    ], 0)
  }
}
rm(r,c)
```

To run the recommendation program, we need to create a "training" set of data and a "test" user for which to recommend artists/bands for.  The first line below simply turns utility values of 0 to missing.  This is a small nuance, but somewhat of an important one.  A utility of 0 indicates an artist that a user has very low (essentially no) preference for, while a missing utility indicates that the user has not listened to any songs by said artist, and therefore has an unknown preference for said artist.  The remaining lines of code simply divide the full sample utility matrix ("samp.Utility") into a training set ("Train.Utility") and a test set/user ("Test.Utility").  The test user is simply just the last user in the full utility matrix, the training set is comprised of users 1 through N-1.
```{r}
samp.Utility[which(samp.Utility == 0)] <- NA
Train.Utility <- samp.Utility[1:N_samp-1,]
Test.Utility <- matrix(samp.Utility[N_samp,], nrow = 1)
colnames(Test.Utility) <- unique(samp.dat$artname)
rownames(Test.Utility) <- rownames(samp.Utility)[N_samp]
```
Ideally the program can make recommendations for any random user drawn from the raw data.  Unfortunately that creates problems for this program, because the library of all possible artists from which to recommend is only defined by the artists listened to by the user sample.  So you can experiment with recommending for different users in the sample (make sure to remove desired user from the training set), but can't recommend for any user who has listened to artists that aren't recognized in the training set.

The code below defines a UBCF recommendation model using functions from the "recommenderlab" package that was loaded at the beginning of the program.  In order to do this, the training and test sets must be identified as "rating matrices" (type: "realRatingMatrix").
```{r}
Train.Affinity <- as(Train.Utility,"realRatingMatrix")
Test.Affinity <- as(Test.Utility, "realRatingMatrix")
Rec.model <- Recommender(data = Train.Affinity, method = "UBCF")
```

Finally, let's make recommendations for the test user.  The code below allows for adjusting the number of recommendations (N_recs) that are made.  The first output shows the artist plays by the test user, the second output shows the top N recommendations for the test user as generated by the recommendation model.
```{r}
N_recs <- 20
recommended.items <- predict(Rec.model, Test.Affinity, n = N_recs)
User.plays <- Lastfm[which(Lastfm$usersha1 == rownames(Test.Utility)),][,c(3:4)] 
User.recs <- as(recommended.items,"list")
User.plays
User.recs
```

All things considered, the model works reasonably well.  But, what are some things to work on moving forward?

First and foremost, I would like to rethink the metric by which I value users' preference for certain artists.  Right now the raw number of plays is the metric I'm using.  There are some shortcomings in using this metric.  For example, does a user who has a total of 1,000 plays and has listened to the Beatles 100 times really like the Beatles as much as a user who has also listened to the Beatles 100 times, but only has a total of 200 plays.  I (and most people I think) would argue, NO!  One consideration might be to put preference metrics on a 0-1 or 0-100 scale, and quantify users' preferences for artists as the proportion of plays alloted to each artist.  So in the example above, UserA's preference for the Beatles might be quanitified as 100/1000 = 0.1, while UserB's preference is 100/200 = 0.5.

I think this idea is certainly a step forward, but even more fine-tuning could be done.  Let's suppose two users who listen to the Beatles 300 times out of their 1,000 total listens (30%).  UserC's listens break down to 300 = Beatles, 300 = Grateful Dead, 400 = Jimi Hendrix.  UserD's listens break down to 300 = Beatles, 100 = Pink Floyd, 100 = Led Zeppelin, 250 = Rolling Stones, and 250 = Elton John each.  I would argue that while both listen to the Beatles 30% of the time, UserD might "like" the Beatles more relative to his other preferences, but his wider range in musical preferences (as reflected by number of unique artists listened to) deflates the propensity Beatles' plays.  Perhaps creating a preference metric for a given artist by a given user that depends on the propoportion of listens alloted to an artist as well as the number of different artists listened to by said user could be a more complete and comprehensive metric of a user's affinity for certain artists/bands.

Lastly, the recommendation model should improve as the training set grows in size; both in number of users and number of unique artists who are listened to.  But building a training set that is much larger than about 200 users is extremely time-inefficient.  I need to figure out how to create large training sets in a timely fashion.  This might require using software other than R.

Create a utility matrix similar to the one created above (samp.Utility), but rather than recording preference values as the number of plays by each user of each artist, preference values will be the percentage of plays that each artist accounts for among all plays by said user (user*artist plays/ total user plays)
```{r}
samp.Utility_perc <- matrix(data = NA, nrow = length(unique(samp.dat$usersha1)),
                       ncol = length(unique(samp.dat$artname)))
rownames(samp.Utility_perc) <- unique(samp.dat$usersha1)
colnames(samp.Utility_perc) <- unique(samp.dat$artname)

# fill in utility matrix for training
for (r in 1:nrow(samp.Utility_perc)) {
  for (c in 1:ncol(samp.Utility_perc)) {
    samp.Utility_perc[r,c] <- max(samp.dat$plays[
      which(samp.dat$artname == colnames(samp.Utility_perc)[c] &
              samp.dat$usersha1 == rownames(samp.Utility_perc)[r])
    ], 0)/sum(samp.dat$plays[which(samp.dat$usersha1 == rownames(samp.Utility_perc)[r])])
  }
}
rm(r,c)
```

Run the recommendation program using "play proportions" as preference value.
```{r}
samp.Utility_perc[which(samp.Utility_perc == 0)] <- NA
Train.Utility_perc <- samp.Utility_perc[1:N_samp-1,]
Test.Utility_perc <- matrix(samp.Utility_perc[N_samp,], nrow = 1)
colnames(Test.Utility_perc) <- unique(samp.dat$artname)
rownames(Test.Utility_perc) <- rownames(samp.Utility_perc)[N_samp]

Train.Affinity_perc <- as(Train.Utility_perc,"realRatingMatrix")
Test.Affinity_perc <- as(Test.Utility_perc, "realRatingMatrix")
Rec.model_perc <- Recommender(data = Train.Affinity, method = "UBCF")

N_recs <- 20
recommended.items_perc <- predict(Rec.model_perc, Test.Affinity_perc, n = N_recs)
User.playlist <- Lastfm[which(Lastfm$usersha1 == rownames(Test.Utility)),][,c(3:4)] 
User.recs_perc <- as(recommended.items_perc,"list")
User.playlist
User.recs_perc
```

